# Kubernetes AI Conformance Checklist
# Notes: This checklist is based on the Kubernetes AI Conformance document.
# Participants should fill in the 'status', 'evidence', and 'notes' fields for each requirement.

metadata:
  kubernetesVersion: v1.33
  platformName: "JCS for Kubernetes"
  platformVersion: "v1.33.3"
  vendorName: "JD Cloud"
  websiteUrl: "https://www.jdcloud.com/en/products/jcs-for-kubernete"
  documentationUrl: "https://docs.jdcloud.com/en/jcs-for-kubernetes/product-overview"
  productLogoUrl: "https://img1.jcloudcs.com/portal/header/jdcloud-logo-2021.svg"
  description: "By adopting fully-hosted management node, JCS for Kubernetes offers simple, easy-to-use, high-reliable and powerful container management service to users. Compatible with Kubernetes API, integrating network, storage and other JD Cloud plug-ins."
contact_email_address: jdcloud@jd.com

spec:
  accelerators:
    - id: dra_support
      description: "Dynamic Resource Allocation (DRA) APIs enable more flexible and fine-grained resource requests beyond simple counts."
      level: SHOULD
      status: ""
      evidence:
        - "https://docs.jdcloud.com/cn/jcs-for-kubernetes/add-gpu"
      notes: "Through device-plugin integration, JCS for Kubernetes provides end users with the capability to dynamically allocate GPU resources to Pod containers, implementing the Dynamic Resource Allocation (DRA) APIs for flexible and fine-grained resource requests."
  networking:
    - id: ai_inference
      description: "Support the Kubernetes Gateway API with an implementation for advanced traffic management for inference services, which enables capabilities like weighted traffic splitting, header-based routing (for OpenAI protocol headers), and optional integration with service meshes."
      level: MUST
      status: "Implemented"
      evidence:
        - "https://docs.jdcloud.com/cn/api-gateway/product-overview"
        - "https://docs.jdcloud.com/cn/jdaip/api-key"
        - "https://docs.jdcloud.com/cn/jdaip/service-invocation-llm"
      notes: ""
  schedulingOrchestration:
    - id: gang_scheduling
      description: "The platform must allow for the installation and successful operation of at least one gang scheduling solution that ensures all-or-nothing scheduling for distributed AI workloads (e.g. Kueue, Volcano, etc.) To be conformant, the vendor must demonstrate that their platform can successfully run at least one such solution."
      level: MUST
      status: "Implemented"
      evidence:
        - "https://docs.jdcloud.com/cn/jdaip/llm-deploy-1"
      notes: "The JD JoyBuild platform which built on JCS for Kubernetes demonstrates gang scheduling conformance by successfully deploying and operating volcano as its primary batch scheduling solution. The platform enables all-or-nothing scheduling for distributed AI workloads, ensuring that multi-pod AI training jobs are either fully scheduled with all required resources or not scheduled at all. This capability is validated through successful execution of AI models using both public container images and user private images, maintaining workload integrity and resource co-location requirements."
    - id: cluster_autoscaling
      description: "If the platform provides a cluster autoscaler or an equivalent mechanism, it must be able to scale up/down node groups containing specific accelerator types based on pending pods requesting those accelerators."
      level: MUST
      status: "Implemented"
      evidence:
        - "https://docs.jdcloud.com/cn/jcs-for-kubernetes/telescopic-nodegroup"
        - "https://docs.jdcloud.com/cn/jcs-for-kubernetes/api/setnodegroupca"
        - "https://docs.jdcloud.com/cn/jdaip/create-and-manage-workspace"
        - "https://docs.jdcloud.com/cn/jdaip/nodepool"
        - "https://docs.jdcloud.com/cn/availability-group/auto-scaling-overview"
      notes: "JCS for Kubernetes demonstrates gang scheduling conformance by successfully deploying and operating Volcano as its primary batch scheduling solution. The platform enables all-or-nothing scheduling for distributed AI workloads, ensuring that multi-pod AI training jobs are either fully scheduled with all required resources or not scheduled at all. This capability is validated through successful execution of AI models using both public container images and user private images, maintaining workload integrity and resource co-location requirements."
    - id: pod_autoscaling
      description: "If the platform supports the HorizontalPodAutoscaler, it must function correctly for pods utilizing accelerators. This includes the ability to scale these Pods based on custom metrics relevant to AI/ML workloads."
      level: MUST
      status: "Implemented"
      evidence:
        - "https://docs.jdcloud.com/cn/jcs-for-kubernetes/cronhpa"
        - "https://docs.jdcloud.com/cn/jdaip/create-queue"
      notes: "JCS for Kubernetes demonstrates HorizontalPodAutoscaler functionality for accelerator-utilizing pods through its CronHPA and AI resource queue mechanisms. The platform enables dynamic scaling of AI/ML workloads based on custom metrics relevant to machine learning operations, such as GPU utilization, training progress, or inference latency. This ensures that pods with accelerators can automatically scale up during high-demand periods and scale down when resources are underutilized, optimizing both performance and cost for AI workloads."
  observability:
    - id: accelerator_metrics
      description: "For supported accelerator types, the platform must allow for the installation and successful operation of at least one accelerator metrics solution that exposes fine-grained performance metrics via a standardized, machine-readable metrics endpoint. This must include a core set of metrics for per-accelerator utilization and memory usage. Additionally, other relevant metrics such as temperature, power draw, and interconnect bandwidth should be exposed if the underlying hardware or virtualization layer makes them available. The list of metrics should align with emerging standards, such as OpenTelemetry metrics, to ensure interoperability. The platform may provide a managed solution, but this is not required for conformance."
      level: MUST
      status: "Implemented"
      evidence:
        - "https://docs.jdcloud.com/cn/monitoring/learning"
        - "https://docs.jdcloud.com/cn/jdaip/monitor"
        - "https://docs.jdcloud.com/cn/jdaip/model-observations"
      notes: "JCS for Kubernetes implements robust accelerator metrics collection using monitor agent, NVIDIA DCGM, and vendor-provided monitoring tools. The platform exposes comprehensive performance metrics through standardized endpoints, covering core requirements like per-GPU utilization and memory usage, plus additional metrics such as thermal data, power metrics, and interconnect bandwidth when supported by hardware. All metrics follow OpenTelemetry conventions for machine-readable format and cross-platform interoperability."
    - id: ai_service_metrics
      description: "Provide a monitoring system capable of discovering and collecting metrics from workloads that expose them in a standard format (e.g. Prometheus exposition format). This ensures easy integration for collecting key metrics from common AI frameworks and servers."
      level: MUST
      status: "Implemented"
      evidence:
        - "https://docs.jdcloud.com/cn/jcs-for-kubernetes/Kubernetes-install-jdmon"
        - "https://docs.jdcloud.com/cn/jcs-for-kubernetes/prometheus-instance-grafana-dashboard"
        - "https://docs.jdcloud.com/cn/jcs-for-kubernetes/custom-pod-metric-notifications"
      notes: "JCS for Kubernetes  provides a fully integrated monitoring system based on Prometheus, which automatically discovers and scrapes metrics endpoints exposed by workloads in the standard Prometheus exposition format, ensuring seamless integration for collecting and displaying key metrics from common AI frameworks and servers."
  security:
    - id: secure_accelerator_access
      description: "Ensure that access to accelerators from within containers is properly isolated and mediated by the Kubernetes resource management framework (device plugin or DRA) and container runtime, preventing unauthorized access or interference between workloads."
      level: MUST
      status: "Implemented"
      evidence:
        - "https://docs.jdcloud.com/cn/jdaip/permission-control"
        - "https://docs.jdcloud.com/cn/virtual-machines/install-GPU"
        - https://docs.jdcloud.com/cn/jcs-for-kubernetes/custom-gpu-driver
        - "https://docs.jdcloud.com/cn/gcs/loginInstance"
      notes: "JCS for Kubernetes ensures proper accelerator isolation and mediation through permission control and its device plugin implementation, which enforces strict resource boundaries within the Kubernetes resource management framework. Only allocated GPUs are accessible within workload containers, preventing unauthorized access or interference between different workloads. The device plugin works in conjunction with the container runtime to mediate all accelerator access, ensuring that each container can only utilize the specific GPU resources assigned to it, thereby maintaining workload isolation and security."
  operator:
    - id: robust_controller
      description: "The platform must prove that at least one complex AI operator with a CRD (e.g., Ray, Kubeflow) can be installed and functions reliably. This includes verifying that the operator's pods run correctly, its webhooks are operational, and its custom resources can be reconciled."
      level: MUST
      status: "Implemented"
      evidence:
        - "https://docs.jdcloud.com/cn/jdaip/create-trainjob"
      notes: "The JD JoyBuild platform, built on JCS for Kubernetes, demonstrates full AI operator support by successfully installing and operating PyTorch and Ray training operators. These complex AI operators with their respective CRDs are fully functional, with all operator pods running correctly, webhooks operational, and custom resources being properly reconciled to support distributed machine learning workloads."
